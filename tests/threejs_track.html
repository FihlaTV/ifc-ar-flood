<!DOCTYPE html>
<html>
<head>
	<title>Iowa Flood Center - Augmented Reality Flood Simulation</title>
	<meta charset="UTF-8"/>
	
	<link href='http://fonts.googleapis.com/css?family=Fauna+One' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="../css/style.css">
	
	<!--load helper libraries-->
	<script type="text/javascript" src="../js/lib/jquery-2.0.1.min.js"></script>
	
	<!--load AR and 3D libraries-->
	<script type="text/javascript" src="../js/lib/three.min.js"></script>
	<script type="text/javascript" src="../js/lib/JSARToolKit.js"></script>
	
	<script>
	$(document).ready(function()
	{
		console.log('Document is ready.');
		
		
		
		var $canvas = $('#mycanvas')[0];
		var threshold = 128;
		
		// Create a RGB raster object for the 2D canvas.
		// JSARToolKit uses raster objects to read image data.
		// Note that you need to set canvas.changed = true on every frame.
		var raster = new NyARRgbRaster_Canvas2D($canvas);

		// FLARParam is the thing used by FLARToolKit to set camera parameters.
		// Here we create a FLARParam for images with 320x240 pixel dimensions.
		var param = new FLARParam(640, 480);

		// The FLARMultiIdMarkerDetector is the actual detection engine for marker detection.
		// It detects multiple ID markers. ID markers are special markers that encode a number.
		var detector = new FLARMultiIdMarkerDetector(param, 120);

		// For tracking video set continue mode to true. In continue mode, the detector
		// tracks markers across multiple frames.
		detector.setContinueMode(true);

		// Copy the camera perspective matrix from the FLARParam to the WebGL library camera matrix.
		// The second and third parameters determine the zNear and zFar planes for the perspective matrix.
		var tmpGlMatCam	= new Float32Array(16);
		param.copyCameraMatrix(tmpGlMatCam, 10, 10000);
		
		
		
		
		//get camera DOM element
		var $video = $('#myvideo');
		if (!$video)
		{
			errorMsg = 'Unable to find <video> element';
			console.log(errorMsg);
			alert(errorMsg);
			return;
		}
		console.log('Found <video> element');
		$video = $video[0];
		
		//stream to video element
		videoId = 0;
		if (videoId == 0)
		{
			//credits: JSARToolkit
			//(https://github.com/kig/JSARToolKit/tree/master/demos/tests/output_4.ogg)
			$video.src = '../resources/videos/output_4.ogg';
		}
		else if (videoId == 1)
		{
			//credits: tquery.jsartoolkit
			//https://github.com/jeromeetienne/tquery.jsartoolkit/tree/master/videos/swap_loop.ogg
			$video.src = '../resources/videos/swap_loop.ogg';
		}
		
		// Create a NyARTransMatResult object for getting the marker translation matrices.
		var resultMat = new NyARTransMatResult();

		var markers = {};
		
		function loop()
		{
			if ($video.readyState === $video.HAVE_ENOUGH_DATA)
			{
				// Draw the video frame to the raster canvas, scaled to 320x240.
				ctx = $canvas.getContext('2d');
				ctx.drawImage($video, 0, 0, 640, 480);

				// Tell the raster object that the underlying canvas has changed.
				$canvas.changed = true;

				// Do marker detection by using the detector object on the raster object.
				// The threshold parameter determines the threshold value
				// for turning the video frame into a 1-bit black-and-white image.
				//
				//NOTE: THE CANVAS MUST BE THE SAME SIZE AS THE RASTER
				//OTHERWISE WILL GET AN "Uncaught #<Object>" ERROR
				var markerCount = detector.detectMarkerLite(raster, threshold);
				
				
				
				

				// Go through the detected markers and get their IDs and transformation matrices.
				for (var idx = 0; idx < markerCount; idx++) {
				  // Get the ID marker data for the current marker.
				  // ID markers are special kind of markers that encode a number.
				  // The bytes for the number are in the ID marker data.
				  var id = detector.getIdMarkerData(idx);
				  

				  // Read bytes from the id packet.
				  var currId = -1;
				  // This code handles only 32-bit numbers or shorter.
				  if (id.packetLength <= 4) {
					currId = 0;
					for (var i = 0; i < id.packetLength; i++) {
					  currId = (currId << 8) | id.getPacketData(i);
					}
				  }
				  console.log(currId);
				  
				  // If this is a new id, let's start tracking it.
				  if (markers[currId] == null) {
					markers[currId] = {};
				  }
				  // Get the transformation matrix for the detected marker.
				  detector.getTransformMatrix(idx, resultMat);

				  // Copy the result matrix into our marker tracker object.
				  markers[currId].transform = Object.asCopy(resultMat);
				  
				  //TODO: draw square
				  //TODO: show id on marker
				}
				
			}
		
			requestAnimationFrame(loop);
		}
		loop();
		
		
		function copyMarkerMatrix(arMat, glMat)
		{
		  glMat[0] = arMat.m00;
		  glMat[1] = -arMat.m10;
		  glMat[2] = arMat.m20;
		  glMat[3] = 0;
		  glMat[4] = arMat.m01;
		  glMat[5] = -arMat.m11;
		  glMat[6] = arMat.m21;
		  glMat[7] = 0;
		  glMat[8] = -arMat.m02;
		  glMat[9] = arMat.m12;
		  glMat[10] = -arMat.m22;
		  glMat[11] = 0;
		  glMat[12] = arMat.m03;
		  glMat[13] = -arMat.m13;
		  glMat[14] = arMat.m23;
		  glMat[15] = 1;
		}
		
		
		//===================================================
		//THREE.JS
		//===================================================
		
		// I'm going to use a glMatrix-style matrix as an intermediary.
		// So the first step is to create a function to convert a glMatrix matrix into a Three.js Matrix4.
		THREE.Matrix4.prototype.setFromArray = function(m) {
		  return this.set(
			m[0], m[4], m[8], m[12],
			m[1], m[5], m[9], m[13],
			m[2], m[6], m[10], m[14],
			m[3], m[7], m[11], m[15]
		  );
		};
		
		
		var renderer	= new THREE.WebGLRenderer({
			antialias	: true
		});
		renderer.setSize(640, 480);
		var $container = $('#threejs-container');
		$container.append(renderer.domElement);

		// create the scene
		var scene	= new THREE.Scene();
		
		

		// glMatrix matrices are flat arrays.
		var tmp = new Float32Array(16);

		// Create a camera and a marker root object for your Three.js scene.
		var camera = new THREE.Camera();
		scene.add(camera);

		var markerRoot = new THREE.Object3D();
		markerRoot.matrixAutoUpdate = false;

		// Add the marker models and suchlike into your marker root object.
		var cube = new THREE.Mesh(
		  new THREE.CubeGeometry(100,100,100),
		  new THREE.MeshBasicMaterial({color: 0xff00ff})
		);
		cube.position.z = -50;
		markerRoot.add(cube);

		// Add the marker root to your scene.
		scene.add(markerRoot);
		
		var material	= new THREE.MeshNormalMaterial();
		var geometry	= new THREE.TorusGeometry( 10, 3 );
		var mesh	= new THREE.Mesh(geometry, material);
		mesh.position.z = -50;
		scene.add(mesh);
		

		// Next we need to make the Three.js camera use the FLARParam matrix.
		param.copyCameraMatrix(tmp, 10, 10000);
		camera.projectionMatrix.setFromArray(tmp);


		// To display the video, first create a texture from it.
		var videoTex = new THREE.Texture($canvas);

		// Then create a plane textured with the video.
		var plane = new THREE.Mesh(
		  new THREE.PlaneGeometry(2, 2, 0),
		  new THREE.MeshBasicMaterial({map: videoTex})
		);

		// The video plane shouldn't care about the z-buffer.
		plane.material.depthTest = false;
		plane.material.depthWrite = false;

		// Create a camera and a scene for the video plane and
		// add the camera and the video plane to the scene.
		var videoCam = new THREE.Camera();
		var videoScene = new THREE.Scene();
		videoScene.add(plane);
		videoScene.add(videoCam);

		// On every frame do the following:
		function tick()
		{
		  // Draw the video frame to the canvas.
		  //$camera.getContext('2d').drawImage(video, 0, 0);
		  $canvas.getContext('2d').drawImage($video, 0, 0, $canvas.width, $canvas.height);

		  // Tell JSARToolKit that the canvas has changed.
		  $canvas.changed = true;

		  // Update the video texture.
		  videoTex.needsUpdate = true;

		  // Detect the markers in the video frame.
		  var markerCount = detector.detectMarkerLite(raster, threshold);
		  for (var i=0; i<markerCount; i++)
		  {
			// Get the marker matrix into the result matrix.
			detector.getTransformMatrix(i, resultMat);

			// Copy the marker matrix to the tmp matrix.
			copyMarkerMatrix(resultMat, tmp);

			// Copy the marker matrix over to your marker root object.
			markerRoot.matrix.setFromArray(tmp);
		  }

		  // Render the scene.
		  renderer.autoClear = false;
		  renderer.clear();
		  renderer.render(videoScene, videoCam);
		  renderer.render(scene, camera);
		  
		  requestAnimationFrame(tick);
		}
		tick();
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		// setup three.js renderer
		/*var renderer	= new THREE.WebGLRenderer({
			antialias	: true
		});
		renderer.setSize(640, 480);
		var $container = $('#threejs-container');
		$container.append(renderer.domElement);

		// create the scene
		var scene	= new THREE.Scene();

		// Create a camera and a marker root object for your Three.js scene.
		var camera = new THREE.PerspectiveCamera(35, renderer.domElement.width/renderer.domElement.height, 1, 10000 );
		camera.position.set(0, 0, 5);
		scene.add(camera);

		// setup lights
		scene.add(new THREE.AmbientLight(0xffffff));

		var light	= new THREE.DirectionalLight(0xffffff);
		light.position.set(3, -3, 1).normalize();
		scene.add(light);

		var light	= new THREE.DirectionalLight(0xffffff);
		light.position.set(-0, 2, -1).normalize();
		scene.add(light);

		var material	= new THREE.MeshNormalMaterial();
		var geometry	= new THREE.TorusGeometry( 10, 3 );
		var mesh	= new THREE.Mesh(geometry, material);
		mesh.position.z = -50;
		scene.add(mesh);

		// Create scene and quad for the video.
		var videoTex 	= new THREE.Texture($camera);
		var geometry	= new THREE.PlaneGeometry(2, 2, 0);
		//TODO: use constant material that is not affected by lighting
		var material	= new THREE.MeshBasicMaterial({
			color		: 0x4444AA,
			color		: 0x6666FF,
			map		: videoTex,
			depthTest	: false,
			depthWrite	: false
		});
		var plane	= new THREE.Mesh(geometry, material );
		var videoScene	= new THREE.Scene();
		var videoCam	= new THREE.Camera();
		videoScene.add(plane);
		videoScene.add(videoCam);
		
		function animate(){	
			requestAnimationFrame(animate);
			render();
		};

		function render(){

			if ( $camera instanceof HTMLVideoElement && $camera.readyState === $camera.HAVE_ENOUGH_DATA ){
				videoTex.needsUpdate	= true;
			}
			
			// trigger the rendering
			renderer.autoClear = false;
			renderer.clear();
			renderer.render(videoScene, videoCam);
			renderer.render(scene, camera);
		};
		
		//animate
		animate();*/
	});
	</script>
</head>
<body>
	<h1>Test 4</h1>
	<h2>Three.js and JSARToolKit tracking background video</h2>
	<div class="invisible" id="video-container">
		<div class="caption">&lt;video&gt;</div>
		<video id="myvideo" width="640" height="480" autoplay="autoplay" muted="true"></video>
	</div>
	<div class="invisible" id="canvas-container">
		<div class="caption">&lt;canvas&gt;</div>
		<canvas id="mycanvas" width="640" height="480"></canvas>
	</div>
	<div class="container" id="threejs-container">
		<div class="caption">threejs</div>
	</div>
	<div class="caption">Instructions: Please see console for tracked marker ID</div>
</body>
</html>